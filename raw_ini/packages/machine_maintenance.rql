
// all the data sources
maint := read("s3://raw-tutorial/ipython-demos/predictive-maintenance/maint.parquet", cache := interval "10 hours");
machines := read("s3://raw-tutorial/ipython-demos/predictive-maintenance/machines.parquet", cache := interval "10 hours");
telemetry := read("s3://raw-tutorial/ipython-demos/predictive-maintenance/telemetry.parquet", cache := interval "10 hours");
failures := read("s3://raw-tutorial/ipython-demos/predictive-maintenance/failures.parquet", cache := interval "10 hours");
errors := read("s3://raw-tutorial/ipython-demos/predictive-maintenance/errors.parquet", cache := interval "10 hours");
machine_data := read("s3://raw-tutorial/ipython-demos/predictive-maintenance/machine_data.parquet", cache := interval "10 hours");

// creates a records to be used as features, one per day, with nested data with:
// measurements over the last days and failures over the next days.  
//      measure_period: period to collected measures in the past days.
//      predict_period: period to try to predict failures over the next days
//      start: start date to collect features from
//      end: end date to collect features from
create_dataset(measure_period: interval, predict_period: interval, start: date, end: date) := {
    in_measure_period(t: timestamp, d: date) := t <= d and t > d - measure_period;
    in_predict_period(t: timestamp, d: date) := t >= d and t < d + predict_period;

    days := select distinct cast(t.datetime as date) date, m.machineID, m.model, m.age
        from telemetry t, machines m
        where t.machineID = m.machineID and t.datetime > start and t.datetime < end;

    select date, machineID, model, age,
            select p.datetime, p.volt, p.rotate, p.vibration from telemetry p
                where p.machineID = machineID and in_measure_period(p.datetime, date)
                as measurements,
            select f.datetime, f.failure from failures f
                where f.machineID = machineID and in_predict_period(f.datetime, date)
                as failures,
            select e.error, e.datetime  from errors e
                where e.machineID=machineID and in_measure_period(e.datetime, date)
                as errors,
            select max(c1.datetime) from maint c1
                where c1.machineID = machineID and c1.comp = "comp1" and c1.datetime <= date
                as lastC1,
            select max(c2.datetime) from maint c2
                where c2.machineID = machineID and c2.comp = "comp2" and c2.datetime <= date
                as lastC2,
            select max(c3.datetime) from maint c3
                where c3.machineID = machineID and c3.comp = "comp3" and c3.datetime <= date
                as lastC3,
            select max(c4.datetime) from maint c4
                where c4.machineID = machineID and c4.comp = "comp4" and c4.datetime <= date
                as lastC4,
            select max(f2.datetime) from failures f2
                where f2.machineID = machineID and f2.datetime <= date
                as lastFailure
        from days

};

//Creates a normalized dataset, (transforms everything to numbers) using the create_dataset function above
dataset_normalized(measure_period: interval, predict_period: interval, start: date, end: date) := {
   to_number(s: string, i: int, l: int := 1) :=  cast(substr(s, i, l) as int);

   select date,
        machineID,
        to_number(model, 6) as model,
        age,
        select avg(m.volt) from measurements m as volt,
        select avg(m.rotate) from measurements m as rotate,
        select avg(m.vibration) from measurements m as vibrate,
        interval_to_millis(date - lastC1 )/ 3600000 as lastC1,
        interval_to_millis(date - lastC2)/ 3600000 as lastC2,
        interval_to_millis(date - lastC3)/ 3600000 as lastC3,
        interval_to_millis(date - lastC4)/ 3600000 as lastC4,
        ccount(errors) as errors,
        isnull(interval_to_millis(date - lastFailure)/ 3600000, -1) as lastFailure,
        if (ccount(failures) > 0)
            then (select to_number(f.failure, 5) from failures f)
            else [0] as failures
    from create_dataset(measure_period, predict_period, start, end)
    where ccount(measurements) > 0
};


//Creates a features, using the dataset_normalized function above
features(measure_period: interval, predict_period: interval, start: date, end: date) := {
       select  [model,
                        age,
                        volt,
                        rotate,
                        vibrate,
                        lastC1,
                        lastC2,
                        lastC3,
                        lastC4,
                        errors,
                        lastFailure] as features,
            failure
        from dataset_normalized(measure_period, predict_period, start, end), failures failure
};

// This is commented now as 
//trains and tests classifier using python and returns record with report
// returns:
//  (
//      used: (training: <number of records used training>, testing: <number of records used testing>),
//      good: (total: <total number of non failures records tested>, correct: <number of correct predictions of non failures>),
//      failure: (total: <total number of failures records tested>, correct: <number of correct predictions of failures>)
//  ) 
//train(url: string, clf: int, train_test: double, fail_good: double) := {
//    typealias t1 := collection(record(features: collection(double nullable), failure: int));
//    typealias t2 := record(correct: int, total: int);
//    typealias t3 := record(good: t1, bad: t1);
//
//    func := \python(data: t3, cl: int, train_test: double, fail_good: double): record( used: record(training: int, testing: int),
//                                                                                      good: t2,
//                                                                                      failure: t2) -> $$$
//        import numpy as np
//        from sklearn.neural_network import MLPClassifier
//        from sklearn.neighbors import KNeighborsClassifier
//        from sklearn.svm import SVC
//        from sklearn.gaussian_process import GaussianProcessClassifier
//        from sklearn.gaussian_process.kernels import RBF
//        from sklearn.tree import DecisionTreeClassifier
//        from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
//        from sklearn.naive_bayes import GaussianNB
//        from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
//
//        classifiers = [
//            KNeighborsClassifier(3),
//            DecisionTreeClassifier(max_depth=5),
//            RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),
//            MLPClassifier(alpha=1, max_iter=1000),
//            AdaBoostClassifier(),
//            GaussianNB(),
//            QuadraticDiscriminantAnalysis()]
//
//        x_good = [v['features'] for v in data['good']]
//        y_good = [v['failure'] for v in data['good']]
//
//        x_bad = [v['features'] for v in data['bad']]
//        y_bad = [v['failure'] for v in data['bad']]
//
//        n_bad = len(x_bad)
//        train_bad = int(n_bad * train_test)
//        train_good = int(train_bad * (1-fail_good) / fail_good)
//
//        test_bad = int(n_bad * (1 - train_test))
//        test_good = int( test_bad * (1 - fail_good) / fail_good)
//
//        train_x = x_good[:train_good] + x_bad[:train_bad]
//        train_y = y_good[:train_good]+ y_bad[:train_bad]
//
//        test_x = x_good[train_good:train_good + test_good] + x_bad[train_bad:]
//        test_y = y_good[train_good:train_good + test_good] + y_bad[train_bad:]
//        clf = classifiers[cl]
//        clf.fit(train_x, train_y)
//        predict = clf.predict(test_x)
//
//        results = {
//           'used': {'training': len(train_x), 'testing': len(test_x)},
//           'good': {'total': 0, 'correct': 0},
//           'failure': {'total': 0, 'correct': 0}
//        }
//        for n, result in enumerate(test_y):
//            v = 'good' if result == 0 else 'failure'
//            results[v]['total'] += 1
//            if result == predict[n]:
//                results[v]['correct'] += 1
//        return results
//    $$$;
//
//    data := (
//        good: select * from read_json[t1](url) where failure = 0,
//        bad: select * from read_json[t1](url) where failure != 0
//    );
//
//    func(data, clf, train_test, fail_good)
//};